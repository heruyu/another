@article{MUTLU2020102359,
title = {Candidate sentence selection for extractive text summarization},
journal = {Information Processing \& Management},
volume = {57},
number = {6},
pages = {102359},
year = {2020},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2020.102359},
url = {https://www.sciencedirect.com/science/article/pii/S0306457320308542},
author = {Begum Mutlu and Ebru A. Sezer and M. Ali Akcayol},
keywords = {Extractive text summarization, Text summarization features, Summarization dataset, Long short-term memory},
abstract = {Text summarization is a process of generating a brief version of documents by preserving the fundamental information of documents as much as possible. Although most of the text summarization research has been focused on supervised learning solutions, there are a few datasets indeed generated for summarization tasks, and most of the existing summarization datasets do not have human-generated goal summaries which are vital for both summary generation and evaluation. Therefore, a new dataset was presented for abstractive and extractive summarization tasks in this study. This dataset contains academic publications, the abstracts written by the authors, and extracts in two sizes, which were generated by human readers in this research. Then, the resulting extracts were evaluated to ensure the validity of the human extract production process. Moreover, the extractive summarization problem was reinvestigated on the proposed summarization dataset. Here the main point taken into account was to analyze the feature vector to generate more informative summaries. To that end, a comprehensive syntactic feature space was generated for the proposed dataset, and the impact of these features on the informativeness of the resulting summary was investigated. Besides, the summarization capability of semantic features was experienced by using GloVe and word2vec embeddings. Finally, the use of ensembled feature space, which corresponds to the joint use of syntactic and semantic features, was proposed on a long short-term memory-based neural network model. ROUGE metrics evaluated the model summaries, and the results of these evaluations showed that the use of the proposed ensemble feature space remarkably improved the single-use of syntactic or semantic features. Additionally, the resulting summaries of the proposed approach on ensembled features prominently outperformed or provided comparable performance than summaries obtained by state-of-the-art models for extractive summarization.}
}

@article{ELKASSAS2021113679,
title = {Automatic text summarization: A comprehensive survey},
journal = {Expert Systems with Applications},
volume = {165},
pages = {113679},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113679},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420305030},
author = {Wafaa S. El-Kassas and Cherif R. Salama and Ahmed A. Rafea and Hoda K. Mohamed},
keywords = {Automatic text summarization, Text summarization approaches, Text summarization techniques, Text summarization evaluation},
abstract = {Automatic Text Summarization (ATS) is becoming much more important because of the huge amount of textual content that grows exponentially on the Internet and the various archives of news articles, scientific papers, legal documents, etc. Manual text summarization consumes a lot of time, effort, cost, and even becomes impractical with the gigantic amount of textual content. Researchers have been trying to improve ATS techniques since the 1950s. ATS approaches are either extractive, abstractive, or hybrid. The extractive approach selects the most important sentences in the input document(s) then concatenates them to form the summary. The abstractive approach represents the input document(s) in an intermediate representation then generates the summary with sentences that are different than the original sentences. The hybrid approach combines both the extractive and abstractive approaches. Despite all the proposed methods, the generated summaries are still far away from the human-generated summaries. Most researches focus on the extractive approach. It is required to focus more on the abstractive and hybrid approaches. This research provides a comprehensive survey for the researchers by presenting the different aspects of ATS: approaches, methods, building blocks, techniques, datasets, evaluation methods, and future research directions.}
}

@Article{Gambhir2017,
author={Gambhir, Mahak
and Gupta, Vishal},
title={Recent automatic text summarization techniques: a survey},
journal={Artificial Intelligence Review},
year={2017},
month={Jan},
day={01},
volume={47},
number={1},
pages={1-66},
abstract={As information is available in abundance for every topic on internet, condensing the important information in the form of summary would benefit a number of users. Hence, there is growing interest among the research community for developing new approaches to automatically summarize the text. Automatic text summarization system generates a summary, i.e. short length text that includes all the important information of the document. Since the advent of text summarization in 1950s, researchers have been trying to improve techniques for generating summaries so that machine generated summary matches with the human made summary. Summary can be generated through extractive as well as abstractive methods. Abstractive methods are highly complex as they need extensive natural language processing. Therefore, research community is focusing more on extractive summaries, trying to achieve more coherent and meaningful summaries. During a decade, several extractive approaches have been developed for automatic summary generation that implements a number of machine learning and optimization techniques. This paper presents a comprehensive survey of recent text summarization extractive approaches developed in the last decade. Their needs are identified and their advantages and disadvantages are listed in a comparative manner. A few abstractive and multilingual text summarization approaches are also covered. Summary evaluation is another challenging issue in this research field. Therefore, intrinsic as well as extrinsic both the methods of summary evaluation are described in detail along with text summarization evaluation conferences and workshops. Furthermore, evaluation results of extractive summarization approaches are presented on some shared DUC datasets. Finally this paper concludes with the discussion of useful future directions that can help researchers to identify areas where further research is needed.},
issn={1573-7462},
doi={10.1007/s10462-016-9475-9},
url={https://doi.org/10.1007/s10462-016-9475-9}
}
@inproceedings{textrank,
    title = "{T}ext{R}ank: Bringing Order into Text",
    author = "Mihalcea, Rada  and
      Tarau, Paul",
    editor = "Lin, Dekang  and
      Wu, Dekai",
    booktitle = "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-3252",
    pages = "404--411",
}
@article{mithe2013optical,
  title={Optical character recognition},
  author={Mithe, Ravina and Indalkar, Supriya and Divekar, Nilam},
  journal={International journal of recent technology and engineering (IJRTE)},
  volume={2},
  number={1},
  pages={72--75},
  year={2013}
}
@inproceedings{rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}
@misc{ISO32000,
  title = {{ISO} 32000:2008},
  author = {{International Organization for Standardization}},
  year = {2008},
  howpublished = {Geneva, Switzerland},
  note = {Document management -- Portable document format -- Part 1: {PDF} 1.7}
}
@misc{F2023,
title={{On-premise vs cloud solutions}: "Choosing the best fit for your business"}, 
url="https://strapi.io/blog/on-premise-vs-cloud-solutions-which-is-the-best-for-your-business", 
journal={On-Premise vs Cloud Solutions: Choosing the Best Fit for Your Business}, 
author="Fagbuyiro, David", 
year="2023", 
month={Feb}} 
@misc{Ho2022, 
title={On premise vs cloud: Whatâ€™s The difference}, 
url={https://blog.tessaract.io/on-premise-vs-cloud-whats-the-difference}, 
journal={Tessaract Blog}, 
author={Ho, Rachel}, 
year={2022}, 
month={May}} 
@software{reactjs,
  author       = {Facebook},
  title        = {React},
  year         = {2013},
  url          = {https://react.dev/},
}
@software{javascript,
  title        = {JavaScript},
  howpublished = {Web Browser},
  year         = {1995},
  url          = {https://developer.mozilla.org/en-US/docs/Web/JavaScript},
}
@software{python,
  title        = {Python},
  author       = {van Rossum, Guido and Python Software Foundation},
  year         = {1991},
  howpublished = {Python Software Foundation},
  url          = {https://www.python.org/},
}
@software{electron,
  title        = {Electron},
  author       = {GitHub, Inc.},
  year         = {2013},
  howpublished = {GitHub Repository},
  url          = {https://github.com/electron/electron},
}
@article{client,
  title={Client-server model},
  author={Oluwatosin, Haroon Shakirat},
  journal={IOSR Journal of Computer Engineering},
  volume={16},
  number={1},
  pages={67--71},
  year={2014},
  publisher={IOSR Journals}
}
@misc{mongodb,
  title = {MongoDB},
  author = {MongoDB, Inc.},
  url = {https://www.mongodb.com/}
}
@inproceedings{novssql,
author = {Parker, Zachary and Poe, Scott and Vrbsky, Susan V.},
title = {Comparing NoSQL MongoDB to an SQL DB},
year = {2013},
isbn = {9781450319010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2498328.2500047},
doi = {10.1145/2498328.2500047},
abstract = {NoSQL database solutions are becoming more and more prevalent in a world currently dominated by SQL relational databases. NoSQL databases were designed to provide database solutions for large volumes of data that is not structured. However, the advantages (or disadvantages) of using a NoSQL database for data that is structured, and not necessarily "Big," is not clear. There are not many studies that compare the performance of processing a modest amount of structured data in a NoSQL database with a traditional relational database. In this paper, we compare one of the NoSQL solutions, MongoDB, to the standard SQL relational database, SQL Server. We compare the performance, in terms of runtime, of these two databases for a modest-sized structured database. Results show that MongoDB performs equally as well or better than the relational database, except when aggregate functions are utilized.},
booktitle = {Proceedings of the 51st ACM Southeast Conference},
articleno = {5},
numpages = {6},
keywords = {structured data, relational, performance, SQL, NoSQL, MongoDB},
location = {Savannah, Georgia},
series = {ACMSE '13}
}
@article{imagg,
author = {D. Lu and Q. Weng},
title = {A survey of image classification methods and techniques for improving classification performance},
journal = {International Journal of Remote Sensing},
volume = {28},
number = {5},
pages = {823-870},
year = {2007},
publisher = {Taylor \& Francis},
doi = {10.1080/01431160600746456},
URL = {https://doi.org/10.1080/01431160600746456},
eprint = {https://doi.org/10.1080/01431160600746456}
}